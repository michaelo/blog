# Om mitt svar til "Hva blir utviklernes st√∏rste utfordring i 2020? üò≤"
## Bakgrunn

Den 9. desember 2019 stilte kode24-redaksjonen f√∏lgende sp√∏rsm√•l p√• deres facebook-gruppe ‚Äú[kode24-klubben](https://www.facebook.com/groups/kode24/)‚Äù (krever medlemskap):
> Hva blir utviklernes st√∏rste utfordring i 2020? üò≤

 \- og svarene der ble da lest opp p√• deres podcast [kode24-timen episode #10](https://share.transistor.fm/s/f6221356).

Jeg tok oppfordringen og startet p√• det som endte opp som en litt komprimert tirade, men det ble allikevel litt langth - og ikke n√∏dvendigvis s√• podcast-vennligt - hvorp√• p√• det ble sagt at dette kanskje kunne v√¶re bedre i bloggformat. S√•, here goes!

Den [opprinnelige kommentaren](#opprinnelig-kommentar) kan leses i sin helhet nederst.


## TL;DR
Alt jeg kommer til √• skrive nedover kommer til syvende √• siste handle om at man m√• vurdere kost mot nytte, samt ta litt samfunnsansvar. Utfordringen er ofte at nytten eller verdien ved √• anvende eller inkorporere et gitt spr√•k, rammeverk, arkitektur/design-pattern, modul e.l. er √•penbar; De respektive l√∏sningene har jo blitt tatt frem for √• l√∏se gitte problemer, mens kostnadene kan v√¶re mange og gjerne ikke gi seg til kjenne f√∏r langt senere.

Jeg mener dermed utviklernes st√∏rste utfordring vil v√¶re √• med h√∏yere presisjon vurdere - og dermed bedre agere p√• - de reelle kostnadene ved sine valg, eventuelt sett fra den andre siden; bli n√∏dt til √• ta konsekvensene av tidligere slike valg.


## Kommentaren, tema for tema

Jeg vil her g√• igjennom de ulike aspektene jeg tok opp i kommentaren. Da jeg favner ganske bredt i alt jeg er innom s√• vil jeg riktignok heller ikke her g√• s√• dypt som jeg kanskje kunne p√• noen av de. Hensikten til denne posten er prim√¶rt √• f√• det hele inn i en mer strukturert form, samt gi det litt mer fylde og med dette danne grunnlag for fremtidige innlegg hvor jeg der heller g√•r mer i dybden p√• de individuelle aspektene.

* _Obs: Jeg er ikke p√• noen m√•te den f√∏rste til √• observere eller mene noe som helst av det jeg skriver her. Ingen √¶re til meg her. Bakgrunnen for √• iterere/repetere over dette er b√•de fordi jeg f√∏ler det fortsatt fokuseres for lite p√• mange av disse aspektene._
* _Obs2: Full √•penhet: Mine egne l√∏sninger innfrir heller ikke alle mine "krav" til optimale systemer/l√∏sninger - men jeg tilstreber det alltid innenfor de rammene jeg har √• jobbe med, og fors√∏ker alltid √• selv bli bedre, samt forbedre litt der jeg kan, og ikke minst: alltid ha kost:nytte med i de store og sm√• vurderingene man fortl√∏pende gj√∏r. Dette er ikke bin√¶rt - eller? \*wink wink*_


### Om gjenbruk
Det har blitt gjentatt og gjenfortalt s√• mange ganger i s√• mange former at man ikke skal finne opp p√• nytt hva som allerede er funnet opp. Argumentet som blir gjort her er gjerne at det du selv improviserer sammen av en funksjon ikke er like godt kvalitetssikret som noe tredjepartskode, samt at det vil koste deg mere tid (og dermed, i mange tilfeller, penger) enn om du finner en eksisterende l√∏sning og bruker denne.

Dette er ikke kategorisk feil, men etter min mening tas dette i mange tilfeller for langt og/eller gj√∏res uten tilstrekkelig vurdering av de reelle kostnadene dette har.

De mer eller mindre generelle ferdigl√∏sningene der ute er lagd med forutinntatte antakelser om hvordan de skal brukes, som kanskje eller kanskje ikke stemmer med dine faktiske omgivelser (f.eks. arkitektur og generell kodestil i prosjektet du jobber i).

Tar vi i tillegg dette opp p√• et makroperspektiv og krisemaksimerer litt ekstra s√• risikerer vi kanskje ogs√• redusert innovasjon og i verste fall at verdifull kompetanse innen enkelte problemomr√•der kan g√• tapt og m√• gjenl√¶res. Samfunns√∏konomisk sett vil jeg sl√• et slag for at det er viktig og riktig √• iblant revurdere gamle l√∏sninger p√• gamle problemer i tillegg til √• l√∏se de s√• langt ul√∏ste problemene. 

Ser man da p√• at mange slike l√∏sninger ogs√• inneholder mer kode/funksjonalitet enn du trenger i ditt scenario legger kan man da ofte legge p√• en gjentakende kostnad for enten deg eller dine brukere, f.eks:

* Kompileres den s√• m√• det tolkes og prosesseres
* Sendes det til nettleser s√• er det ekstra data b√•de √• sende og √• tolke
* Og selv om mye kan optimaliseres bort s√• gir du her ekstra arbeid til ett eller annet sted i bygge-pipelinen din og p√• det vis √∏ker det fortsatt tiden du bruker for hver iterasjon

I tillegg har du de velkjente problemene rundt hvorvidt l√∏sningen er vedlikeholdt, at du opererer innenfor lisensvilk√•rene, og avhengig av hvordan du spesifiserer dine avhengigheter s√• kan du v√¶re utsatt for senere introduksjon av feil i nye versjoner. Du er uansett ansvarlig for ditt sluttprodukt.

Jeg kunne ogs√• skrevet litt om misoppfatninger rundt "<acronym title="Don't Repeat Yourself">DRY</acronym>" og "design patterns"-misbruk ogs√• - men det f√•r bli for en annen gang.


### Om abstraksjoner
En abstraksjon er i all sin enkelhet et fors√∏k p√• √• trekke seg unna, skjule, eller p√• annet vis √• beskrive noe annerledes enn slik det originalt ble gjort ([wikipedia](https://en.wikipedia.org/wiki/Abstraction), [webster](https://www.merriam-webster.com/dictionary/abstraction)). I programvareutvikling fors√∏ker man ofte √• abstrahere for √•:
* gjemme detaljer man ikke √∏nsker √• trenge forholde seg til til vanlig - f.eks. gjentakende kode eller kompliserte operasjoner som kanskje krever spesiell kunnskap for √• mestre (f.eks. algoritmer)
* definere og skille moduler/komponenter/subsystemer man √∏nsker √• frikoble seg fra for √• enklere kunne teste, erstatte og/eller jobbe med uavhengig av hverandre
* kunne st√∏tte multiple varianter/tilbydere av en funksjon/subsystem (f.eks: periferiutstyr, plugins)

*Man kan selvsagt ogs√• argumentere for at enhver form for enkapsulering av noe (f.eks. en funksjon) er en form for abstraksjon, men jeg tenker her p√• de litt st√∏rre, bevisste, arkitekturelle eller designmessige valgene man gj√∏r.*

I tillegg s√• ser man i lys av "dependency injection"-b√∏lgen at enkelte prosjekter velger √• beskrive formelle grensesnitt for _enhver_ klasse, og (min favoritt\</sarkasme>) registrerer alle disse i et container-system som automagisk sl√•r opp og genererer de faktiske objektene eller hva det n√• skulle v√¶re p√• bakgrunn av dette.

Felles for de alle er at noen da gj√∏r en vurdering om hvilke muligheter og hva slags data som skal skjules og eksponeres, og definerer dermed et grensesnitt basert p√• dette.

Risikoen her kommer da til syne n√•r man f√∏rst har laget en abstraksjon, og denne har blitt tatt i bruk over b√•de tid og rom, og det kommer et behov for √• revidere denne p√• et vis som bryter bakoverkompatibilitet. Ligger denne abstraksjonen p√• et tilstrekkelig h√∏yt nok niv√• i arkitekturen s√• har man kanskje iverksatt et versjoneringsregime for √• h√•ndtere denne typen endringer, men uansett ligger det da en kost i √• enten oppdatere alle konsumenter, eller √• ivareta multiple l√∏sninger i parallell. Men i tillegg til de *eksplisitte* avhengighetene s√• har vi de *implisitte* avhengighetene man hadde lurt seg til √• tro man var trygg for takket v√¶re at man hadde lagd nettopp disse fine abstraksjonene.

For min del er utsagn som "Dette spr√•ket er S√Ö h√∏yniv√• at du ikke trenger √• tenke p√• minneh√•ndtering|raceconditions|parallelitet" eller "Dette rammeverket abstraherer vekk alle dine _\<sett inn problemdomene her>_-problemer" √• se som store varsellamper. Det er ingen av de som sier noe om hva du _mister_, s√• det m√• vi som gode utviklere l√¶re oss √• lese mellom linjene.


### Om kompleksitet, ytelse, maskinvare og utviklertid

Hvert nytt lag av noe som helst du legger p√• l√∏sningen din √∏ker kompleksiteten. Dette, ironisk nok, til tross for at lagene ofte introduseres for √• skjule kompleksitet. Det er ogs√• uavhengig av om dette gj√∏res direkte i koden, i bygge-pipelinen, i deployment-regimet eller i infrastrukturen ellers. Dette er da hensyn som p√• ulike tidspunkt vil m√•tte v√¶re en del av utviklerens [kognitive belastning](https://twitter.com/detly/status/394755439314755584) n√•r du enten vurderer konsekvensen av funksjonen du legger til, eller er p√• lusejakt.

Det er et knippe utsagn jeg gj√∏r i kommentaren som g√•r innom disse temaene:

> Argumenter som at utviklertid er mer kostbar enn hardware m√∏ter seg selv n√•r man <del>man</del> snubler over bugs og flaskehalser som kommer fra alt fra underliggende √•rsaker som man enten ikke forst√•r til utilstrekkelige og/eller dype abstraksjoner som det vil v√¶re fryktelig kostbare √• endre [...]

Igjen: dette kommer tilbake til en kost:nytte-vurdering. Man kan alltids iterere, simplifisere og/eller optimalisere inn i evigheten - det er ikke det jeg mener man skal. Men gi det noen runder, og v√¶r klar over implikasjonene det har √• legge til nye dimensjoner til en l√∏sning. Rich Hickey har noen gode poeng rundt [enkelt vs simpelt](https://www.infoq.com/presentations/Simple-Made-Easy/) - spesielt definisjonsmessig - som er bra √• ta med seg. Han g√•r riktignok der ikke inn p√• temaet kj√∏retidsytelse. Hovedpoenget han gj√∏r er √• presisere at det er forskjell p√• noe som er en lett tilgjengelig l√∏sning for _deg_, _n√•_, sammenliknet med hva som er en _ukomplisert_ l√∏sning som er lett √• forst√• og jobbe med ogs√• i ettertid.

> [...] det er ikke akkurat som at OSene vi har i dag er veldig HW-effektive og robuste heller... Dette av historiske grunner, men dog.

Det jeg refererer til her er det at de fleste st√∏rre allment brukte operativsystem b√¶rer med seg en stor teknisk gjeld og et sett bakoverkompatibilitetsrelaterte problemer knyttet til blant annet behov for √• st√∏tte en stor mengde ulike perifere enheter og systemarkitekturer. Og i noen av disse tilfellene legger da operativsystemet seg p√• et "minste fellesnevner"-niv√• mtp anvendelse av hardwarekapabilitetene, og realiserer ting som n√• i mange tilfeller er l√∏st i hardwaren/firmwaren til periferienheten i software i stedet (Se f.eks. [denne om potensiell ytelsesgevinst ved √• retenke hva ansvaret til et operativsystem kan v√¶re](https://www.usenix.org/node/186141)). Dette byr p√• flere linjer kode som i ulik grad tar med seg en eller flere av utfordringene jeg nevner i denne posten, i tillegg til at det h√∏rer til sjeldenhetene at kode eksekvert p√• en CPU for generelle form√•l (CISC/RISC) utklasserer spesialisert firmware kj√∏rende p√•/for dedikert maskinvare. [Casey Muratori gjorde noen interessante betraktninger noen √•r tilbake](https://www.youtube.com/watch?v=kZRE7HIO3vk) rundt det med at vi n√• ikke lenger eksperimenterer like mye rundt arkitekturer og typer perifere enheter og s√•nn sett kunne hatt mye √• hente p√• √• flytte litt mer ansvar til hardware, revidere systembusgrensesnittet og p√• det viset redusere mye av hva et operativsystem ville trengt √• v√¶re. Jeg er ikke selv n√∏dvendigvis 100% enig i alt det han konkret legger frem, men finner det vanskelig √• v√¶re uenig i det store bildet.

> [...] det ikke er uvanlig √• h√∏re argumenter som at "ubrukt RAM er sl√∏st RAM" [...]

_Obs: Dette er min subjektive tolkning av et knippe ulike utsagn h√∏rt igjennom tidene, samt hva som oppleves som √• v√¶re praksis med tanke p√• den mengde ressurser generelt, og RAM spesielt, som brukes normalt i dag._

Beslektede argumenter her er at RAM er s√• billig eller at m√•lgruppen din kanskje uansett har s√•-og-s√• mye RAM allikevel.

Dette er kanskje et av de mest problematiske problemstillingene jeg kommer borti n√•r jeg som en utvikler av ganske s√• beskjedne systemer m√• ha 16GB+ med RAM bare for at jeg ikke skal havne i [minneswaporamaland](https://www.howtogeek.com/128130/htg-explains-why-its-good-that-your-computers-ram-is-full/). For meg vitner dette om manglende respekt for sluttbrukerens tid og ressurser.

S√•nn jeg ser det er denne type utsagn kun gyldig i noen tilfeller der du _vet uten tvil_ at ditt system er det aller viktigste (les: typisk eneste) som kj√∏rer p√• den gitte maskinvaren/ressursbassenget i perioden det m√•tte gjelde - eller om du gir brukeren mulighet til √• kontrollere dette. Det hjelper ikke at operativsystemet fors√∏ker √• v√¶re intelligent n√•r applikasjonen enten ikke er √¶rlig om sine reelle behov, eller bare helt enkelt er overkonsumerende.

Vi nyttiggj√∏r oss ofte heller ikke veldig mye av den veldig avanserte maskinvaren vi n√• etterhvert har f√•tt, med effektive l√∏sninger rundt pipelining, cacheh√•ndtering, branch predictions mm n√•r vi ikke viser litt omsorg til dataene som faktisk skal prosesseres. Ja, den m√∏rke hemmeligheten til programmering er at til syvende og sist handler det kun om data som skal leses, kalkuleres p√• og skrives. 

**Veldig anekdotisk om ytelsespotensiale:** I desember deltok jeg (og 431 andre) p√• [knowits kodekalender](https://julekalender.knowit.no/), og det jeg kanskje fant mest givende med hele den opplevelsen er "sluttspillet" som oppsto da alle de som hadde l√∏st en gitt oppgave kunne diskutere sine l√∏sninger i et eget kommentarfelt. Der s√• vi l√∏sninger i en mengde spr√•k, i henhold til et knippe paradigmer, ulike algoritmiske tiln√¶rminger og med ulik grad av optimalisering. F.eks. kunne vi for [luke 23](https://gist.github.com/knowitkodekalender/65d7a798df1b121148bade6d50b29bde) observere forskjeller i kj√∏retid fra [1m52s til <5ms](https://raw.githubusercontent.com/terjew/AdventOfCode2019/master/progress.png) (Takk til terjew for grafen! Denne viser kj√∏retid, s√• det er noe usagt her rundt minnebruk naturligvis). N√• er heller ikke problemene vi ble konfrontert med der n√∏dvendigvis direkte 1:1 sammenliknbare for hva folk flest l√∏ser til daglig, men det viste fortsatt mye av spennet av hva valg av algoritme, teknologi samt omsorg for maskinvare kan ha √• si. Python-l√∏sningen som kj√∏rte p√• ~30s var en helt kurant l√∏sning i seg selv (ganske pythonistisk for hva jeg er i stand til √• bed√∏mme), mens en tilsvarende ganske naiv l√∏sning i C f√∏rst havnet p√• ~1s enkelttr√•det, og ~0.23s 8-tr√•det, f√∏r det s√• oppstod en kollaborativ innsats der en mindre gruppe virkelig begynte √• se hvor langt man klarte √• dra det. Her kan vi selvsagt diskutere avkastningen i forhold til tiden brukt for √• ta oss hele veien ned til ~5ms - og dette vil v√¶re avhengig av faktisk problemdomene.

Bare for √• ha det sagt: vi s√• ogs√• C++-l√∏sninger opp i 20s-spekteret, dette er ikke kun et poeng om spr√•k og kompilator. Det er i de fleste forslagene der brukt ulike algoritmiske tiln√¶rminger og mange av m√•lingene er gjort p√• ulik maskinvare - spesielt initielt. De observante vil ogs√• se at de (kj√∏retids-)effektive l√∏sningene gjerne ogs√• bestod av mer kode og s√•nn sett kan √∏ke risikoen for feil samt gj√∏r det vanskeligere √• tilpasse over tid. Det er ikke en l√∏sning √• hyperoptimalisere _alt_, men jeg f√∏ler det fortsatt sier noe om potensialet ved √• legge litt kj√¶rlighet i det man lager.

En annen tanke: Det jeg for√∏vrig kunne tenke meg er √• se noen vurderinger gjort p√• et makroperspektiv, der man ser p√• dette sammen med f.eks. st√∏rrelsen p√• serverparkene til Google, Microsoft, Facebook og Amazon. Det er et milj√∏perspektiv her: Disse skal produseres, forsynes med str√∏m, og etterhvert deponeres/gjenvinnes. Hva ville det gjort om gjennomsnittsforbruket av RAM for en gjennomsnittlig applikasjon redusertes med 10%? 20%? 50%? Og dette samsvarende med tilsvarende √∏kning i effektiviteten av CPU-bruk? Det finnes riktignok tider hvor man m√• gj√∏re et kompromiss av typen: bruke mere RAM for √• redusere CPU-belastning, eller omvendt, men jeg vil allikevel p√•st√• at det i _mange_ tilfeller er mulig √• forbedre begge to.

Jeg har en frykt - som jeg √∏nsker √• finne kvalitative tall for eller mot p√•, men har ikke lykkes s√• langt - om at programvarekompleksitet (herunder systemer) √∏ker raskere enn maskinvareytelsen. I s√• fall er mye av praten rundt horisontal skalering (dvs som *standard* go-to-l√∏sning ved ytelsesproblemer) og tilsvarende aspekter av skyl√∏sninger √• anse som kortsiktig tenking: vi har kj√∏pt oss litt tid, det fungerer umiddelbart, men hvor mye l√∏ser det egentlig p√• lang sikt hvis dette fortsetter slik?


### Om testkode

Jeg kaster inn en liten parentes som lyder som f√∏lger:
> [...] (gjerne akkompagnert med 2:1 testkode:kode-ratio) [...]

En √∏rliten klarifisering: Det er ikke slik at jeg er imot testkode (automatiserte tester realisert som kode) - tvert imot. Det er et fantastisk bra og viktig verkt√∏y. I tillegg var ikke 2:1 det mest illustrative forholdstallet rundt hva som er √• anse problematisk mengde. Jeg tenker her ogs√• p√• automatiserte tester generelt, og knytter ikke det direkte for/mot utviklingsmetodologier.

Det jeg ganske enkelt √∏nsker at utviklere skal v√¶re bevisste p√• er at ogs√• dette er med p√• √• √∏ke egenmassen til kodebasen og dermed har en p√•virkning p√• endringsmomentet til en l√∏sning. Velkjente argumenter utover √• verifisere at den gitte kodesnutten oppf√∏rer som forventet er at de lar deg refaktorere uten frykt samt gir deg en ekstra advarsel ved endring p√• grensesnittene. Men om man gj√∏r endringer som enten p√•virker de eksplisitte avhengighetene (funksjonssignaturer/API-overflate) eller de implisitte avhengighetene (de som - forh√•pentligvis utilsiktet og ogs√• u√∏nsket - baserer seg p√• s√¶regenheter i den aktuelle implementasjonen) s√• m√• man ogs√• oppdatere testkoden tilsvarende. Dette _tar_ tid. Forh√•pentligvis er verdien h√∏y nok over tid til √• forsvare dette.

N√•r det kommer til forholdet mellom mengde testkode sett opp mot mengde implementasjonskode, som igjen helst b√∏r ha en viss korrelasjon til faktisk testdekning for √• gi mening, s√• ser jeg det som naturlig at dette samsvarer med kritikaliteten av programvaren som utvikles: Det er forskjell p√• enkle kommandolinjegrensesnitt, nettsider, sm√• og store nettapplikasjoner, bibliotekskode, rammeverk og safetykritiske systemer. I tillegg b√∏r det v√¶re tatt stilling til de potensielt √∏konomiske implikasjonene feil vil ha. Eller for √• snu rundt p√• det: antall brukere som potensielt vil v√¶re p√•virket, og i hvilken grad det da vil p√•virke de.

Jeg tror ikke noe av det jeg skriver her er sjokkerende, men vet selv hvor lett det er √• la seg rive med n√•r endorfinrushet fra dekningsgraden som √∏ker, kombineres med en liten dose tvangstankeliknende stolthet i perfeksjonisme og [bransjep√•virkere som trekker relasjoner mellom <acronym title="Test Driven Development">TDD</acronym> og hygieniske krav til kirurger](https://blog.cleancoder.com/uncle-bob/2014/05/02/ProfessionalismAndTDD.html).

## Opprinnelig kommentar

[Det opprinnelige svaret mitt](https://www.facebook.com/groups/kode24/permalink/1246653578857041/?comment_id=1246697968852602) (krever medlemskap i gruppen) var som f√∏lger:


> En invitasjon til ranting (y) jo =) Jeg tar den jeg.
> 
> \<rant>
> Det er nok dessverre ikke det som vil _eksplodere_ i 2020, men jeg antar at vi kommer til √• se fortsettelsen p√• abstraksjons-og-gjenbruks-toget som har p√•g√•tt i mange √•r n√•:
> 
> Spr√•k, teknologier, rammeverk mm markedsf√∏res (og slukes) p√• premisset rundt at vi skal i bunn og grunn ikke trenge √• forholde oss til det faktum at koden vi skriver faktisk til syvende og sist skal kj√∏res p√• hardware, samt en hellig overbevisning at all skriving av egen kode som funksjonelt ligner p√• noe noen har lagt ut p√• npm/cargo/maven/nuget/... er un√∏dvendig.
> 
> Argumenter som at utviklertid er mer kostbar enn hardware m√∏ter seg selv n√•r man <del>man</del> snubler over bugs og flaskehalser som kommer fra alt fra underliggende √•rsaker som man enten ikke forst√•r til utilstrekkelige og/eller dype abstraksjoner som det vil v√¶re fryktelig kostbare √• endre da "arkitekturen" f.eks. best√•r av (tilfeldig sammensatt eksempel her alts√•) en kompilert-til-JS-applikasjon (gjerne akkompagnert med 2:1 testkode:kode-ratio) med 100+ avhengigheter, bundlet med Chromium, pakket inn i en docker-container, kj√∏rende i en eller annen sky/cluster-tjeneste (som gjerne er en abstraksjon over Kubernetes igjen) f√∏r det til slutt snakker med et faktisk OS.
> 
> Og det er ikke akkurat som at OSene vi har i dag er veldig HW-effektive og robuste heller... Dette av historiske grunner, men dog.
> 
> Kunne ogs√• sagt noe her om bruk av RAM ogs√•, der det ikke er uvanlig √• h√∏re argumenter som at "ubrukt RAM er sl√∏st RAM" (fritt sitert). Argument som sett i isolasjon kan gi mening (OK nok i et embedded milj√∏ der man har full kontroll p√• alt som skal kj√∏re), men som i desktop-milj√∏er f√∏rer til at n√•r man s√•nn som enkelte av oss √∏nsker √• ha flere applikasjoner kj√∏rende samtidig s√• trenger man 16GB+ RAM bare for √• ha et par utviklingsmilj√∏-instanser.
> 
> (Ja, jeg er klar over at jeg skj√¶rer applikasjon+infrastruktur over samme lest her)
> (Og ja, jeg vet at ingen av disse synspunktene har sitt opp<del>g</del>hav fra meg. Men jeg videreformidler med "glede")
> (Og alle tall er semi-tilfeldig plukket basert p√• observasjoner)
> \</rant>
> 
> Obs: Dette var ikke en rant (kun) om web - det har v√¶rt symptomatisk innen de omr√•dene jeg har rukket √• bes√∏ke i mitt yrkesaktive liv.
> 
> Ellers ser jeg lyst p√• tilv√¶relsen jeg alts√•!
